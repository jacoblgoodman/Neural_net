{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artistic-level",
   "metadata": {},
   "source": [
    "# 1. the sigmoid proof\n",
    "\n",
    "Show that the derivative of the sigmoid function given above is given by:\n",
    "\n",
    "    𝜕𝜎(𝑥)\n",
    "𝜕𝑥 = 𝜎(𝑥)(1 − 𝜎(𝑥))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-council",
   "metadata": {},
   "source": [
    "tests\n",
    "## remebering the sigmoid function:\n",
    "$$ \n",
    "\\partial\\sigma(x)= \\partial(\\frac{1}{1+e^{-x}})\n",
    "$$\n",
    "\n",
    "## remembering the formula for quotients\n",
    "$$\n",
    "\\frac{dy}{dx}\\left(\\frac{f(x)}{f(g)}\\right) \n",
    "=\n",
    "\\frac{\\frac{d}{dx}\\left(f(x)\\right)  g(x) -  f(X)\\frac{d}{dx}\\left(g(x)\\right) }  {[g(x)]^2}\n",
    "$$\n",
    "\n",
    "## breaking it into peices for sigmoid\n",
    "$$\n",
    "f'(x) = 0 \\newline\n",
    "g'(x) = -e^{-x}\n",
    "$$\n",
    "## spelling it out \n",
    "$$\n",
    "\\frac{0(1+e^{-x})-1(-e^{-x})            }\n",
    "     {\\left(1+e^{-x}\\right)^2}\n",
    "$$\n",
    "## result\n",
    "\n",
    "$$\n",
    "\\frac{e^{-x}}\n",
    "     {\\left(1+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "## below we will verify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "inside-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{e^{- x}}{\\left(1 + e^{- x}\\right)^{2}}$"
      ],
      "text/plain": [
       "exp(-x)/(1 + exp(-x))**2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import E, diff \n",
    "from sympy.abc import x\n",
    "import numpy as np\n",
    "expr = 1/(1+E**-x)\n",
    "#diff(a*log(a) - a + 1, x)\n",
    "diff(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-coordination",
   "metadata": {},
   "source": [
    "We have verified our differentiation but I am still unsure how to get it into the requested form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-disclosure",
   "metadata": {},
   "source": [
    "# 2. testing forward propegartion to predicts\n",
    "Here are the initial weights:\n",
    "WEIGHTS  \n",
    "\n",
    "|Link from node| Link to node| Weight|\n",
    "|---|---|---|\n",
    "Input 1 |Hidden 1| 0.1\n",
    "Input 1 |Hidden 2| 0.3\n",
    "Input 1 |Hidden 3| −0.2\n",
    "Input 2 |Hidden 1| −0.4\n",
    "Input 2 |Hidden 2| 0.1\n",
    "Input 2 |Hidden 3| 0.2\n",
    "Input 3 |Hidden 1| −0.1\n",
    "Input 3 |Hidden 2| −0.2\n",
    "Input 3 |Hidden 3| 0.4\n",
    "Hidden 1 |Out 1 |0.5\n",
    "Hidden 1 |Out 2 |0.2\n",
    "Hidden 2 |Out 1 |−0.3\n",
    "Hidden 2 |Out 2 |−0.3\n",
    "Hidden 3 |Out 1 |0.2\n",
    "Hidden 3 |Out 2 |0.1\n",
    "BIAS WEIGHTS\n",
    "Layer| Weight \n",
    "Hidden| 0.2\n",
    "Output |0.3\n",
    "\n",
    "\n",
    "**steps** \n",
    "using these weights we will calculate a prediction and error for the following input  \n",
    "\n",
    "\n",
    "\n",
    "|input 1| input 2| input 3| Output 1| Output 2|\n",
    "| -     | -      | -      |    -    |   -     |\n",
    "|4|8|6|.65|.4|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-shelter",
   "metadata": {},
   "source": [
    "## populating our first weight matrix and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consolidated-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "[[ 0.1  0.3 -0.2]\n",
      " [-0.4  0.1  0.2]\n",
      " [-0.1 -0.2  0.4]\n",
      " [ 0.2  0.2  0.2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 8, 6, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#to input -> hiden knode weights \n",
    "w =np.array([[.1,.3,-.2],[-.4,.1,.2],[-.1,-.2,.4],[.2,.2,.2]])\n",
    "print(w.shape)\n",
    "print(w)\n",
    "inp = np.array([4,8,6,1])\n",
    "inp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-relative",
   "metadata": {},
   "source": [
    "## calculating our weighted sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "competent-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.2,  1. ,  3.4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whid=inp.dot(w)\n",
    "whid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "soviet-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity checking\n",
    "4*.1 + 8*-.4 + 6*-.1 + .2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-browser",
   "metadata": {},
   "source": [
    "## transformating hidden node with sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worth-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a sigmoid function sigmoid\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "completed-hospital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying the sigmoid \n",
    "Thid = np.append(sigmoid(whid),1)\n",
    "Thid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-correspondence",
   "metadata": {},
   "source": [
    "## populating our second weight table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pleased-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.2],\n",
       "       [-0.3, -0.3],\n",
       "       [ 0.2,  0.1],\n",
       "       [ 0.3,  0.3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to out from hidden node weights\n",
    "W =np.array([[.5,.2],[-.3,-.3],[.2,.1],[.3,.3]])\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-permit",
   "metadata": {},
   "source": [
    "## finding the weighted sum of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "knowing-truth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29380619, 0.18528602])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating Weighted output\n",
    "Wout=Thid.dot(W)\n",
    "Wout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "defined-murray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5729277 , 0.54618944])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## applying the sigmoid and getting our outputs\n",
    "Tout = sigmoid(Wout)\n",
    "Tout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-canberra",
   "metadata": {},
   "source": [
    "## now putting it all together into one function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "national-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5729277 , 0.54618944])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.append(sigmoid(inp.dot(w)),1).dot(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fitting-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5729277 , 0.54618944])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a function for later:\n",
    "def predict(inp,w,W,func=sigmoid):\n",
    "    return func(np.append(func(inp.dot(w)),1).dot(W))\n",
    "predict(inp,w,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liked-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65, 0.4 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = np.array([.65,.4])\n",
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "moderate-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023885891017721714"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = (sum(targ - Tout)**2)*.5\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-japanese",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "latin-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"our sigmoid activation funciton \"\"\"\n",
    "    import numpy as np #importing dependencies as is best practice \n",
    "    return 1/(1+np.e**(-x))\n",
    "\n",
    "\n",
    "def error(targ, pred):\n",
    "    \"\"\" error function\"\"\"\n",
    "    return  (sum(targ - pred)**2)*.5\n",
    "\n",
    "def predict(inp,w,W,func=sigmoid, y=None):\n",
    "    \"\"\"this function takes in inputs, weight matrix, and an activation function and makes a predication \"\"\"\n",
    "    pred = func(np.append(func(inp.dot(w)),1).dot(W))\n",
    "    if E is None: \n",
    "        return pred\n",
    "    else: \n",
    "        \n",
    "        return error(y, pred)\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "innovative-warrant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023885891017721714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(inp,w,W,y=targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-greene",
   "metadata": {},
   "source": [
    "# 3.working on backware propegaation:\n",
    "\n",
    "**our back propegation several steps:**\n",
    "1. find and store our gradients:  \n",
    "   As we are trying to minimize our errors the gradients we find are for the funciton for are from each weight and bias to the Error term.  \n",
    "    1. first step find gradients for output to hidden\n",
    "        1. for all hidden nodes and output nodes Gradiants for\n",
    "        2. for BiasO for all output nodes\n",
    "    3. second step find gradients for hidden to input\n",
    "        1. for all hidden nodes and inputs \n",
    "        2. for BiasH for all hidden nodes \n",
    "    4.  use calcualted gradients to apply update to weights\n",
    "        \n",
    "\n",
    "**functions and informaiton we need to power our gradients:**\n",
    "\n",
    "* input information: inputs, target outputs, weight matrix's \n",
    "* cacluated iformaiton: \n",
    "    * Thid - our activated hiden nodes values  with respect to our input \n",
    "    * Tout - our predictations with respect to our input \n",
    "* funcs\"\n",
    "    * derivit funciton of our error function with respect to E \n",
    "    * derivitive funciton of  our activatiion function  \n",
    "\n",
    "\n",
    "**Detailed steps:**\n",
    "1. initalize matrix's g and G of shape IxH and HxO where I is Num_inputs, H is Num_hideen nodes, and O is num_ outputs \n",
    "2. initializ 2 bias arrays if len H and O \n",
    "3. use a nested for loop to cacluate for all weights between all hidden and output noodes the gradient with resepect to each weight:\n",
    "    3. first caculate the Bias term for kth output node\n",
    "    4. use the bias term for k and multipy by the jth hidden node to  to find the gradeints each hidden node j output node k \n",
    "    5. store the biask for use in later caculatations\n",
    "        * special care has to be taken here biases must be summed before being utlized in gradiant updates\n",
    "4. use a nested for loop to calculate for all weights between  all input and hidden noedes the gradient with repect to each weight:\n",
    "    1. for each hidden node j and bias k from the previous step find the dot product between weight vector and biases\n",
    "    2. find the bias for each hidden node j\n",
    "    3. use the bias for hidden node j and multiply for each input i to find the gradient for each weight i,j \n",
    "    4. update Biash with bias term\n",
    "5. update gradient matrixs\n",
    "    1. for hidden to output gradient matrix\n",
    "        1. sum bias vector and then appened to matrix\n",
    "    2. for input to hiddne gradient matrix\n",
    "        1. append bias vector \n",
    "5. apply gradients to weights using formula $weight-\\alpha*gradient$ we will use alpha .2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-lancaster",
   "metadata": {},
   "source": [
    "## initalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "armed-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 3\n",
    "num_hidden = 3\n",
    "num_outputs = 2\n",
    "\n",
    "# intialize matrix and vectors\n",
    "G = np.zeros((num_hidden,num_outputs))\n",
    "g = np.zeros((num_inputs,num_hidden))\n",
    "Bo = np.zeros((1,num_outputs))\n",
    "Bh = np.zeros((1,num_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "registered-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our derivitive error function\n",
    "def Der_error(pred,target):\n",
    "    return pred-target\n",
    "# set up our derivitive activation function\n",
    "def Der_sigmoid(val):\n",
    "    return val *(1-val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-palestine",
   "metadata": {},
   "source": [
    "## first step back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pretty-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.loop and cacluate gradiants and  bias for first step back \n",
    "\n",
    "\n",
    "for k in range(num_outputs):\n",
    "    #caculate for an output node \n",
    "    Bias = Der_error(Tout[k],targ[k])*Der_sigmoid(Tout[k])\n",
    "    for j in range(num_hidden):\n",
    "        #add for hidden node \n",
    "        G[j,k]=Bias*Thid[j]\n",
    "    \n",
    "    #upate bias vectore\n",
    "    Bo[0,k] = Bias #note this will be summed before utlized in updates but information stored here can be utlized in next step\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-mumbai",
   "metadata": {},
   "source": [
    "## second step back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "authorized-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop and caculate gradients and  bias for second step back\n",
    "for k in range(num_hidden):\n",
    "    bias = Bo.dot(W[k,:])*Der_sigmoid(Thid[k])\n",
    "    for j in range(num_inputs):\n",
    "        g[j,k] = bias*inp[j]\n",
    "    Bh += bias #updating all biaas because we aren't using these values again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-highway",
   "metadata": {},
   "source": [
    "##   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "elementary-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up gradient arrays \n",
    "\n",
    "#sum Bo\n",
    "Bo[:] = np.sum(Bo)\n",
    "G = np.append(G,Bo,axis=0)\n",
    "g = np.append(g,Bh,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "classified-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update weights \n",
    "\n",
    "W_new = W-.2*G\n",
    "w_new = w-.2*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "behavioral-dover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10006569,  0.30081998, -0.1999963 ],\n",
       "       [-0.39986862,  0.10163996,  0.2000074 ],\n",
       "       [-0.09990147, -0.19877003,  0.40000555],\n",
       "       [ 0.20022234,  0.20022234,  0.20022234]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-gathering",
   "metadata": {},
   "source": [
    "# 4. bulding everything together\n",
    "\n",
    "we will now take all the steps above and encode them into a CLass object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "competent-highway",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-586196812cab>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-586196812cab>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    __init__(self,num_Inputs,num_Outputs,num_HiddenNodes,errorfunc=Square_error,activation=sigmoid):\u001b[0m\n\u001b[1;37m                                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class neural_network:\n",
    "    __init__(self,num_Inputs,num_Outputs,num_HiddenNodes,errorfunc=Square_error,activation=sigmoid):\n",
    "        \n",
    "        \n",
    "        self._num_Inputs =num_Inputs\n",
    "        self._num_Outputs = num_Outputs\n",
    "        self._num_HiddenNodes = num_HiddenNodes\n",
    "        \n",
    "        if errorfunc ==Square_error:\n",
    "            self.errorfunc = Square_error\n",
    "            self.Der_errorfunc = Der_Square_error\n",
    "        \n",
    "        if activation == sigmoid:\n",
    "            self.actfunc = sigmoid\n",
    "            self.Der_evtfunc = Der_sigmoid\n",
    "        \n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "        self.w = rng.(-5,5,size=num_HiddenNodes*num_Inputs)\n",
    "        self.w.reshape((num_inputs,num_HiddenNodes))\n",
    "        \n",
    "        \n",
    "    def matrix_initalization(self):\n",
    "        rng = np.random.default_rng()\n",
    "        w = rng.integers(-5,5,size=self._num_HiddenNodes*self._num_Inputs)\n",
    "        self.w = w.reshape((num_inputs,num_HiddenNodes))\n",
    "        \n",
    "        W = rng.integers(-5,5,size=self._num_HiddenNodes*self._num_Outputs)\n",
    "        self.W = W.reshape(self._)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
