{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "czech-offset",
   "metadata": {},
   "source": [
    "# Activation function proofs\n",
    "\n",
    "To utlize and activation function in our neural network we need to know both the function we want to use and its derivative. \n",
    "\n",
    "While many options exist to find the derivatives for us including progromatic python solvers and just googling. The point of this repo is to demonstrate that we have learned the nessasary skills to do this work ourselves and such we will right out the process in Laytex and then verify our results via other means below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-festival",
   "metadata": {},
   "source": [
    "# 1. the sigmoid proof\n",
    "\n",
    "Show that the derivative of the sigmoid function given above is given by:\n",
    "\n",
    "    ùúïùúé(ùë•)\n",
    "ùúïùë• = ùúé(ùë•)(1 ‚àí ùúé(ùë•))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-persian",
   "metadata": {},
   "source": [
    "## remebering the sigmoid function:\n",
    "$$ \n",
    "\\partial\\sigma(x)= \\partial(\\frac{1}{1+e^{-x}})\n",
    "$$\n",
    "\n",
    "## remembering the formula for quotients\n",
    "$$\n",
    "\\frac{dy}{dx}\\left(\\frac{f(x)}{f(g)}\\right) \n",
    "=\n",
    "\\frac{\\frac{d}{dx}\\left(f(x)\\right)  g(x) -  f(X)\\frac{d}{dx}\\left(g(x)\\right) }  {[g(x)]^2}\n",
    "$$\n",
    "\n",
    "## breaking it into peices for sigmoid\n",
    "$$\n",
    "f'(x) = 0 \\newline\n",
    "g'(x) = -e^{-x}\n",
    "$$\n",
    "## spelling it out \n",
    "$$\n",
    "\\frac{0(1+e^{-x})-1(-e^{-x})            }\n",
    "     {\\left(1+e^{-x}\\right)^2}\n",
    "$$\n",
    "## result\n",
    "\n",
    "$$\n",
    "\\frac{e^{-x}}\n",
    "     {\\left(1+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "## below we will verify the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "agreed-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{e^{- x}}{\\left(1 + e^{- x}\\right)^{2}}$"
      ],
      "text/plain": [
       "exp(-x)/(1 + exp(-x))**2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import E, diff \n",
    "from sympy.abc import x\n",
    "from sympy.solvers import solve\n",
    "import numpy as np\n",
    "expr = 1/(1+E**-x)\n",
    "\n",
    "diff(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-anchor",
   "metadata": {},
   "source": [
    "# 2. The hyperbolic tangent\n",
    "Find the deriviative of the hyperbolic tangent function:  \n",
    "\n",
    "\n",
    "$f(x)= \\frac{e^x-e^{-x}}{e^x+e^{-x}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-woman",
   "metadata": {},
   "source": [
    "## spelling out the problem:\n",
    "\n",
    "$$ \n",
    "\\partial\\sigma(x)= \\partial\\left(\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\right) \n",
    "$$\n",
    "\n",
    "## finding the peices for the quotient rule \n",
    " refer above to sigmoid for refersher on the quotient rule\n",
    "\n",
    "$$  \n",
    "f'(x) = e^{x}+e^{-x} \\newline\n",
    "g'(x) = e^{x}-e^{-x}\n",
    "$$\n",
    "\n",
    "## factoring out \n",
    "$$\n",
    "\\frac{(e^{x}+e^{-x})(e^x+e^{-x})-(e^x-e^{-x})(e^{x}-e^{-x})}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "## simplifying\n",
    "### step 1\n",
    "$$\n",
    "\\frac{(e^{x}+e^{-x})^2-(e^x-e^{-x})^2}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "$$\n",
    "### step 2\n",
    "$$\n",
    "\\frac{(e^{x}+e^{-x})^2}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "-\n",
    "\\frac{(e^x-e^{-x})^2}\n",
    "     {\\left(e^x+e^{-x}\\right)^2}\n",
    "$$\n",
    "## result\n",
    "$$\n",
    "1-\\left(\\frac{e^x-e^{-x}}\n",
    "             {e^x+e^{-x}}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "joint-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\left(- e^{x} + e^{- x}\\right) \\left(e^{x} - e^{- x}\\right)}{\\left(e^{x} + e^{- x}\\right)^{2}} + 1$"
      ],
      "text/plain": [
       "(-exp(x) + exp(-x))*(exp(x) - exp(-x))/(exp(x) + exp(-x))**2 + 1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = (E**x-E**-x)/(E**x+E**-x)\n",
    "#diff(a*log(a) - a + 1, x)\n",
    "\n",
    "diff(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-optics",
   "metadata": {},
   "source": [
    "difference here can be explained in how the -(e^x+e^-x) term was handled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-brooks",
   "metadata": {},
   "source": [
    "## a different approach to hyperbolic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-straight",
   "metadata": {},
   "source": [
    "### solving the pollynomials\n",
    "\n",
    "### starting here\n",
    "$$\n",
    "\\frac{(e^{x}+e^{-x})(e^x+e^{-x})-(e^x-e^{-x})(e^{x}-e^{-x})}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "### solving \n",
    "\n",
    "$$\n",
    "\\frac{(e^{2x}+e^{-2x}+2)-(e^{2x}+e^{-2x}-2)}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "### finishing\n",
    "$$\n",
    "\\frac{4}\n",
    "     {\\left(e^x+e^{-x}\\right)^2} \n",
    "$$\n",
    "\n",
    "we now need to test these 2 different approachs for equalaity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "indonesian-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9900662908474398\n",
      "0.9610429829661166\n",
      "0.9151369618266292\n",
      "0.8556387860811777\n",
      "0.7864477329659274\n",
      "0.7115777625872228\n",
      "0.6347395899824587\n",
      "0.5590551677322441\n",
      "0.4869173611483416\n"
     ]
    }
   ],
   "source": [
    "def aproach_1(x):\n",
    "    return (1-((np.e**x-np.e**-x)/(np.e**x+np.e**-x))**2)\n",
    "\n",
    "for e in range(0,10,1):\n",
    "    print(aproach_1(e/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sapphire-harvard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9900662908474399\n",
      "0.9610429829661166\n",
      "0.9151369618266293\n",
      "0.8556387860811775\n",
      "0.7864477329659275\n",
      "0.7115777625872229\n",
      "0.6347395899824588\n",
      "0.5590551677322441\n",
      "0.48691736114834155\n"
     ]
    }
   ],
   "source": [
    "def approach_2(x):\n",
    "    return 4/(np.e**x+np.e**-x)**2\n",
    "\n",
    "for e in range(0,10,1):\n",
    "    print(approach_2(e/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-newcastle",
   "metadata": {},
   "source": [
    "# 3. ReLU\n",
    "Rectified linear unit is on of the most popular activation functions. this is due to its simplistiy and becuase it helps reduce vanishing gradient problems. We will prove out the derivitive and then add to our nueral network. we will see the simplisity in action  \n",
    "\n",
    "\n",
    "\n",
    "## initial function\n",
    "$f(x)=max(0,x)$  \n",
    "OR  \n",
    "$\n",
    "\\begin{cases}\n",
    "0 &\\text{for }  x<0 \\\\\n",
    "x &\\text{for }  x\\geq0\n",
    "\\end{cases}\n",
    "$\n",
    "## explaining\n",
    "the relu function has 2 options.\n",
    "1. when x is less than 0 we return 0 \n",
    "    1. 0 is a constant so its deriviative is 0 \n",
    "2. when x is greater than or equal to 0 we return x \n",
    "    2. the derivative of x is 1    \n",
    "\n",
    "Therefore\n",
    "## deriviative \n",
    "$$\n",
    "\\begin{cases}\n",
    "0 &\\text{for }  x<0 \\\\\n",
    "1 &\\text{for }  x\\geq0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "wired-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding the function\n",
    "def der_relu(x:float):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def act_relu(x:float):\n",
    "    return max(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "varying-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(act_relu(-5))\n",
    "print(act_relu(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "suspected-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(der_relu(-5))\n",
    "print(der_relu(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
